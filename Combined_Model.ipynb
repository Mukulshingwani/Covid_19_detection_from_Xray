{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Combined_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dzs52y-986Gi",
        "outputId": "782e7973-066f-4243-de09-4bc12499ff20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "R00QK97LIK6i"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Mg_cysYrt-82"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path_raw = '/content/drive/MyDrive/PRML Project/covid 19/Combinedmodel_Dataset/raw_cxr/'\n",
        "dataset_path_masked = '/content/drive/MyDrive/PRML Project/covid 19/Combinedmodel_Dataset/masked_cxr/'\n",
        "dataset_path_invmasked = '/content/drive/MyDrive/PRML Project/covid 19/Combinedmodel_Dataset/invmasked_cxr/'"
      ],
      "metadata": {
        "id": "X0EFKyHakZ9s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms.transforms import RandomHorizontalFlip\n",
        "dataset_transforms2 = transforms.Compose([\n",
        "                                          transforms.Resize((224,224)), \n",
        "                                          transforms.RandomHorizontalFlip(),\n",
        "                                          transforms.RandomRotation(10),\n",
        "                                          transforms.ToTensor(),\n",
        "                                        ])"
      ],
      "metadata": {
        "id": "sMt3fVVekykg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_raw = torchvision.datasets.ImageFolder(root = dataset_path_raw, transform = dataset_transforms2)\n",
        "dataset_masked = torchvision.datasets.ImageFolder(root = dataset_path_masked, transform = dataset_transforms2)\n",
        "dataset_invmasked = torchvision.datasets.ImageFolder(root = dataset_path_invmasked, transform = dataset_transforms2)"
      ],
      "metadata": {
        "id": "n190bzValJ0x"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4"
      ],
      "metadata": {
        "id": "lW_hsMTwy8m7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset_raw), len(dataset_masked), len(dataset_invmasked)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNL8aX88pyKD",
        "outputId": "7baa6cbd-5849-4091-ae5e-0dc7e21abeb9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 5000, 5000)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(dataset_raw))\n",
        "validation_size = int(0.1 * len(dataset_raw))\n",
        "test_size = len(dataset_raw) - train_size - validation_size\n",
        "train_dataset_raw, validation_dataset_raw, test_dataset_raw = torch.utils.data.random_split(dataset_raw, [train_size,validation_size,test_size])"
      ],
      "metadata": {
        "id": "rqYtwy1dp4ur"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_raw = torch.utils.data.DataLoader(dataset = train_dataset_raw, batch_size = batch_size)\n",
        "valid_loader_raw = torch.utils.data.DataLoader(dataset = validation_dataset_raw, batch_size = batch_size)\n",
        "test_loader_raw = torch.utils.data.DataLoader(dataset = test_dataset_raw, batch_size = batch_size)"
      ],
      "metadata": {
        "id": "Pxqqe9_7qkAb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(dataset_masked))\n",
        "validation_size = int(0.1 * len(dataset_masked))\n",
        "test_size = len(dataset_masked) - train_size - validation_size\n",
        "train_dataset_masked, validation_dataset_masked, test_dataset_masked = torch.utils.data.random_split(dataset_masked, [train_size,validation_size,test_size])"
      ],
      "metadata": {
        "id": "GzMVFTelqEe9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_masked = torch.utils.data.DataLoader(dataset = train_dataset_masked, batch_size = batch_size)\n",
        "valid_loader_masked = torch.utils.data.DataLoader(dataset = validation_dataset_masked, batch_size = batch_size)\n",
        "test_loader_masked = torch.utils.data.DataLoader(dataset = test_dataset_masked, batch_size = batch_size)"
      ],
      "metadata": {
        "id": "o9ZwNQq5qpVT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.7 * len(dataset_invmasked))\n",
        "validation_size = int(0.2 * len(dataset_invmasked))\n",
        "test_size = len(dataset_invmasked) - train_size - validation_size\n",
        "train_dataset_invmasked, validation_dataset_invmasked, test_dataset_invmasked = torch.utils.data.random_split(dataset_invmasked, [train_size,validation_size,test_size])"
      ],
      "metadata": {
        "id": "AGhrkMZ-qVVW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_invmasked = torch.utils.data.DataLoader(dataset = train_dataset_invmasked, batch_size = batch_size)\n",
        "valid_loader_invmasked = torch.utils.data.DataLoader(dataset = validation_dataset_invmasked, batch_size = batch_size)\n",
        "test_loader_invmasked = torch.utils.data.DataLoader(dataset = test_dataset_invmasked, batch_size = batch_size)"
      ],
      "metadata": {
        "id": "wuXeZGb-qdaN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for (i1, (f1,l1)), (i2, (f2,l2)), (i3, (f3,l3)) in zip(enumerate(train_loader_raw), enumerate(train_loader_masked), enumerate(train_loader_invmasked)):\n",
        "#   print(\"----------------\")\n",
        "#   print(i1)\n",
        "#   print(f1)\n",
        "#   print(\"----------------\")\n",
        "#   print(i2)\n",
        "#   print(f2)\n",
        "#   print(\"----------------\")\n",
        "#   print(i3)\n",
        "#   print(f3)\n",
        "#   break"
      ],
      "metadata": {
        "id": "L_WHvS-gq9vO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_idx, (features, targets) in enumerate(train_loader_raw):\n",
        "  print(batch_idx)\n",
        "  print(features.size())\n",
        "  print(targets.size())\n",
        "  print(targets)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMAxZHyh1S2z",
        "outputId": "8a3c5d50-8013-4e85-e411-d29d8c49a1bd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "torch.Size([4, 3, 224, 224])\n",
            "torch.Size([4])\n",
            "tensor([1, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_idx, (features, targets) in enumerate(train_loader_masked):\n",
        "  print(batch_idx)\n",
        "  print(features.size())\n",
        "  print(targets.size())\n",
        "  print(targets)\n",
        "  break"
      ],
      "metadata": {
        "id": "c17IccGq2lvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k=0\n",
        "lis = []\n",
        "for i, (f,l) in enumerate(train_loader_raw):\n",
        "  lis.append((i, (f,l)))"
      ],
      "metadata": {
        "id": "OahpXgOV2P2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (batch_idx1, (features1, targets1)), (batch_idx2, (features2,targets2)), (batch_idx3, (features3,targets3)) in zip(enumerate(train_loader_raw), enumerate(train_loader_masked), enumerate(train_loader_invmasked)):\n",
        "  print(batch_idx1)\n",
        "  print(features1.size())\n",
        "  print(targets1.size())\n",
        "  print(targets1)\n",
        "  break\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eSVCf6r1Pxq",
        "outputId": "7de0381e-48ea-4671-8d6c-4e3a61cb6aaf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "torch.Size([4, 3, 224, 224])\n",
            "torch.Size([4])\n",
            "tensor([0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SukYi4CT9EQZ"
      },
      "outputs": [],
      "source": [
        "# imports from installed libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "from distutils.version import LooseVersion as Version\n",
        "from itertools import product\n",
        "\n",
        "def set_all_seeds(seed):\n",
        "    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "def set_deterministic(use_tensorcores=False):\n",
        "    if torch.cuda.is_available():\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "    if torch.__version__ <= Version(\"1.7\"):\n",
        "        torch.set_deterministic(True)\n",
        "    else:\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "        \n",
        "        # The following are set to True by default and allow cards\n",
        "        # like the Ampere and newer to utilize tensorcores for\n",
        "        # convolutions and matrix multiplications, which can result\n",
        "        # in a significant speed-up. However, results may differ compared\n",
        "        # to card how don't use mixed precision via tensor cores.\n",
        "        torch.backends.cuda.matmul.allow_tf32 = use_tensorcores\n",
        "        torch.backends.cudnn.allow_tf32 = use_tensorcores\n",
        "\n",
        "\n",
        "def compute_accuracy(model, data_loader_raw, data_loader_masked, data_loader_invmasked, device):\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        correct_pred, num_examples = 0, 0\n",
        "\n",
        "        for (i1, (features1, targets1)), (i2, (features2,targets2)), (i3, (features3,targets3)) in zip(enumerate(train_loader_raw), enumerate(train_loader_masked), enumerate(train_loader_invmasked)):\n",
        "\n",
        "            i = i1\n",
        "            features1 = features1.to(device)\n",
        "            features2 = features2.to(device)\n",
        "            features3 = features3.to(device)\n",
        "            targets = targets1.float().to(device)\n",
        "\n",
        "            logits = model(features1, features2, features3)\n",
        "            _, predicted_labels = torch.max(logits, 1)\n",
        "\n",
        "            num_examples += targets.size(0)\n",
        "            correct_pred += (predicted_labels == targets).sum()\n",
        "    return correct_pred.float()/num_examples * 100\n",
        "\n",
        "\n",
        "def compute_confusion_matrix(model, data_loader_raw, data_loader_masked, data_loader_invmasked, device):\n",
        "\n",
        "    all_targets, all_predictions = [], []\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for (i1, (features1, targets1)), (i2, (features2,targets2)), (i3, (features3,targets3)) in zip(enumerate(train_loader_raw), enumerate(train_loader_masked), enumerate(train_loader_invmasked)):\n",
        "            i = i1\n",
        "            features1 = features1.to(device)\n",
        "            features2 = features2.to(device)\n",
        "            features3 = features3.to(device)\n",
        "            targets = targets1\n",
        "            logits = model(features1, features2, features3)\n",
        "            _, predicted_labels = torch.max(logits, 1)\n",
        "            all_targets.extend(targets.to('cpu'))\n",
        "            all_predictions.extend(predicted_labels.to('cpu'))\n",
        "\n",
        "    all_predictions = all_predictions\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_targets = np.array(all_targets)\n",
        "        \n",
        "    class_labels = np.unique(np.concatenate((all_targets, all_predictions)))\n",
        "    if class_labels.shape[0] == 1:\n",
        "        if class_labels[0] != 0:\n",
        "            class_labels = np.array([0, class_labels[0]])\n",
        "        else:\n",
        "            class_labels = np.array([class_labels[0], 1])\n",
        "    n_labels = class_labels.shape[0]\n",
        "    lst = []\n",
        "    z = list(zip(all_targets, all_predictions))\n",
        "    for combi in product(class_labels, repeat=2):\n",
        "        lst.append(z.count(combi))\n",
        "    mat = np.asarray(lst)[:, None].reshape(n_labels, n_labels)\n",
        "    return mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9TP-V4Cgi3g9"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "\n",
        "def train_model(model, num_epochs, train_loader_raw,\n",
        "                valid_loader_raw, test_loader_raw, train_loader_masked,\n",
        "                valid_loader_masked, test_loader_masked, train_loader_invmasked,\n",
        "                valid_loader_invmasked, test_loader_invmasked, optimizer,\n",
        "                device, logging_interval=50,\n",
        "                scheduler=None,\n",
        "                scheduler_on='valid_acc'):\n",
        "\n",
        "    start_time = time.time()\n",
        "    minibatch_loss_list, train_acc_list, valid_acc_list = [], [], []\n",
        "    \n",
        "    best_acc = 0\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        model.train()\n",
        "        for (batch_idx1, (features1, targets1)), (batch_idx2, (features2,targets2)), (batch_idx3, (features3,targets3)) in zip(enumerate(train_loader_raw), enumerate(train_loader_masked), enumerate(train_loader_invmasked)):\n",
        "            \n",
        "            # batch_idx1, batch_idx2, and batch_idx3 are all same.\n",
        "            batch_idx = batch_idx1\n",
        "            features1 = features1.to(device)\n",
        "            features2 = features2.to(device)\n",
        "            features3 = features3.to(device)\n",
        "            # targets1, targets2, and target3 are all same.\n",
        "            targets = targets1.to(device)\n",
        "\n",
        "            # ## FORWARD AND BACK PROP\n",
        "            logits = model(features1, features2, features3)\n",
        "            loss = torch.nn.functional.cross_entropy(logits, targets)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # ## UPDATE MODEL PARAMETERS\n",
        "            optimizer.step()\n",
        "\n",
        "            # ## LOGGING\n",
        "            minibatch_loss_list.append(loss.item())\n",
        "            if not batch_idx % logging_interval:\n",
        "                print(f'Epoch: {epoch+1:03d}/{num_epochs:03d} '\n",
        "                      f'| Batch {batch_idx:04d}/{len(train_loader_raw):04d} '\n",
        "                      f'| Loss: {loss:.4f}')\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():  # save memory during inference\n",
        "            train_acc = compute_accuracy(model, train_loader_raw, train_loader_masked, train_loader_invmasked, device=device)\n",
        "            valid_acc = compute_accuracy(model, valid_loader_raw, valid_loader_masked, valid_loader_invmasked, device=device)\n",
        "            print(f'Epoch: {epoch+1:03d}/{num_epochs:03d} '\n",
        "                  f'| Train: {train_acc :.2f}% '\n",
        "                  f'| Validation: {valid_acc :.2f}%')\n",
        "            train_acc_list.append(train_acc.item())\n",
        "            valid_acc_list.append(valid_acc.item())\n",
        "\n",
        "        if(valid_acc.item() > best_acc):\n",
        "          best_acc = valid_acc.item()\n",
        "          torch.save(model.state_dict(), f'/content/drive/MyDrive/PRML Project/covid 19/M4_weights/m4_02_05_{valid_acc.item()}.pt')\n",
        "\n",
        "        elapsed = (time.time() - start_time)/60\n",
        "        print(f'Time elapsed: {elapsed:.2f} min')\n",
        "        \n",
        "        if scheduler is not None:\n",
        "\n",
        "            if scheduler_on == 'valid_acc':\n",
        "                scheduler.step(valid_acc_list[-1])\n",
        "            elif scheduler_on == 'minibatch_loss':\n",
        "                scheduler.step(minibatch_loss_list[-1])\n",
        "            else:\n",
        "                raise ValueError(f'Invalid `scheduler_on` choice.')\n",
        "        \n",
        "\n",
        "    elapsed = (time.time() - start_time)/60\n",
        "    print(f'Total Training Time: {elapsed:.2f} min')\n",
        "\n",
        "    test_acc = compute_accuracy(model, test_loader_raw, test_loader_masked, test_loader_invmasked, device=device)\n",
        "    print(f'Test accuracy {test_acc :.2f}%')\n",
        "\n",
        "    return minibatch_loss_list, train_acc_list, valid_acc_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Ich8ZSuh9MDe"
      },
      "outputs": [],
      "source": [
        "# imports from installed libraries\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "def plot_training_loss(minibatch_loss_list, num_epochs, iter_per_epoch,\n",
        "                       results_dir=None, averaging_iterations=100):\n",
        "\n",
        "    plt.figure()\n",
        "    ax1 = plt.subplot(1, 1, 1)\n",
        "    ax1.plot(range(len(minibatch_loss_list)),\n",
        "             (minibatch_loss_list), label='Minibatch Loss')\n",
        "\n",
        "    if len(minibatch_loss_list) > 1000:\n",
        "        ax1.set_ylim([\n",
        "            0, np.max(minibatch_loss_list[1000:])*1.5\n",
        "            ])\n",
        "    ax1.set_xlabel('Iterations')\n",
        "    ax1.set_ylabel('Loss')\n",
        "\n",
        "    ax1.plot(np.convolve(minibatch_loss_list,\n",
        "                         np.ones(averaging_iterations,)/averaging_iterations,\n",
        "                         mode='valid'),\n",
        "             label='Running Average')\n",
        "    ax1.legend()\n",
        "\n",
        "    ###################\n",
        "    # Set scond x-axis\n",
        "    ax2 = ax1.twiny()\n",
        "    newlabel = list(range(num_epochs+1))\n",
        "\n",
        "    newpos = [e*iter_per_epoch for e in newlabel]\n",
        "\n",
        "    ax2.set_xticks(newpos[::10])\n",
        "    ax2.set_xticklabels(newlabel[::10])\n",
        "\n",
        "    ax2.xaxis.set_ticks_position('bottom')\n",
        "    ax2.xaxis.set_label_position('bottom')\n",
        "    ax2.spines['bottom'].set_position(('outward', 45))\n",
        "    ax2.set_xlabel('Epochs')\n",
        "    ax2.set_xlim(ax1.get_xlim())\n",
        "    ###################\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if results_dir is not None:\n",
        "        image_path = os.path.join(results_dir, 'plot_training_loss.pdf')\n",
        "        plt.savefig(image_path)\n",
        "\n",
        "\n",
        "def plot_accuracy(train_acc_list, valid_acc_list, results_dir):\n",
        "\n",
        "    num_epochs = len(train_acc_list)\n",
        "\n",
        "    plt.plot(np.arange(1, num_epochs+1),\n",
        "             train_acc_list, label='Training')\n",
        "    plt.plot(np.arange(1, num_epochs+1),\n",
        "             valid_acc_list, label='Validation')\n",
        "\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if results_dir is not None:\n",
        "        image_path = os.path.join(\n",
        "            results_dir, 'plot_acc_training_validation.pdf')\n",
        "        plt.savefig(image_path)\n",
        "\n",
        "\n",
        "def show_examples(model, data_loader, unnormalizer=None, class_dict=None):\n",
        "    \n",
        "        \n",
        "    for batch_idx, (features, targets) in enumerate(data_loader):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            features = features\n",
        "            targets = targets\n",
        "            logits = model(features)\n",
        "            predictions = torch.argmax(logits, dim=1)\n",
        "        break\n",
        "\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=5,\n",
        "                             sharex=True, sharey=True)\n",
        "    \n",
        "    if unnormalizer is not None:\n",
        "        for idx in range(features.shape[0]):\n",
        "            features[idx] = unnormalizer(features[idx])\n",
        "    nhwc_img = np.transpose(features, axes=(0, 2, 3, 1))\n",
        "    \n",
        "    if nhwc_img.shape[-1] == 1:\n",
        "        nhw_img = np.squeeze(nhwc_img.numpy(), axis=3)\n",
        "\n",
        "        for idx, ax in enumerate(axes.ravel()):\n",
        "            ax.imshow(nhw_img[idx], cmap='binary')\n",
        "            if class_dict is not None:\n",
        "                ax.title.set_text(f'P: {class_dict[predictions[idx].item()]}'\n",
        "                                  f'\\nT: {class_dict[targets[idx].item()]}')\n",
        "            else:\n",
        "                ax.title.set_text(f'P: {predictions[idx]} | T: {targets[idx]}')\n",
        "            ax.axison = False\n",
        "\n",
        "    else:\n",
        "\n",
        "        for idx, ax in enumerate(axes.ravel()):\n",
        "            ax.imshow(nhwc_img[idx])\n",
        "            if class_dict is not None:\n",
        "                ax.title.set_text(f'P: {class_dict[predictions[idx].item()]}'\n",
        "                                  f'\\nT: {class_dict[targets[idx].item()]}')\n",
        "            else:\n",
        "                ax.title.set_text(f'P: {predictions[idx]} | T: {targets[idx]}')\n",
        "            ax.axison = False\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(conf_mat,\n",
        "                          hide_spines=False,\n",
        "                          hide_ticks=False,\n",
        "                          figsize=None,\n",
        "                          cmap=None,\n",
        "                          colorbar=False,\n",
        "                          show_absolute=True,\n",
        "                          show_normed=False,\n",
        "                          class_names=None):\n",
        "\n",
        "    if not (show_absolute or show_normed):\n",
        "        raise AssertionError('Both show_absolute and show_normed are False')\n",
        "    if class_names is not None and len(class_names) != len(conf_mat):\n",
        "        raise AssertionError('len(class_names) should be equal to number of'\n",
        "                             'classes in the dataset')\n",
        "\n",
        "    total_samples = conf_mat.sum(axis=1)[:, np.newaxis]\n",
        "    normed_conf_mat = conf_mat.astype('float') / total_samples\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    ax.grid(False)\n",
        "    if cmap is None:\n",
        "        cmap = plt.cm.Blues\n",
        "\n",
        "    if figsize is None:\n",
        "        figsize = (len(conf_mat)*1.25, len(conf_mat)*1.25)\n",
        "\n",
        "    if show_normed:\n",
        "        matshow = ax.matshow(normed_conf_mat, cmap=cmap)\n",
        "    else:\n",
        "        matshow = ax.matshow(conf_mat, cmap=cmap)\n",
        "\n",
        "    if colorbar:\n",
        "        fig.colorbar(matshow)\n",
        "\n",
        "    for i in range(conf_mat.shape[0]):\n",
        "        for j in range(conf_mat.shape[1]):\n",
        "            cell_text = \"\"\n",
        "            if show_absolute:\n",
        "                cell_text += format(conf_mat[i, j], 'd')\n",
        "                if show_normed:\n",
        "                    cell_text += \"\\n\" + '('\n",
        "                    cell_text += format(normed_conf_mat[i, j], '.2f') + ')'\n",
        "            else:\n",
        "                cell_text += format(normed_conf_mat[i, j], '.2f')\n",
        "            ax.text(x=j,\n",
        "                    y=i,\n",
        "                    s=cell_text,\n",
        "                    va='center',\n",
        "                    ha='center',\n",
        "                    color=\"white\" if normed_conf_mat[i, j] > 0.5 else \"black\")\n",
        "    \n",
        "    if class_names is not None:\n",
        "        tick_marks = np.arange(len(class_names))\n",
        "        plt.xticks(tick_marks, class_names, rotation=90)\n",
        "        plt.yticks(tick_marks, class_names)\n",
        "        \n",
        "    if hide_spines:\n",
        "        ax.spines['right'].set_visible(False)\n",
        "        ax.spines['top'].set_visible(False)\n",
        "        ax.spines['left'].set_visible(False)\n",
        "        ax.spines['bottom'].set_visible(False)\n",
        "    ax.yaxis.set_ticks_position('left')\n",
        "    ax.xaxis.set_ticks_position('bottom')\n",
        "    if hide_ticks:\n",
        "        ax.axes.get_yaxis().set_ticks([])\n",
        "        ax.axes.get_xaxis().set_ticks([])\n",
        "\n",
        "    plt.xlabel('predicted label')\n",
        "    plt.ylabel('true label')\n",
        "    return fig, ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "AeRlHi3Y9lD0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import sampler\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import SubsetRandomSampler\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "class UnNormalize(object):\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        ------------\n",
        "        tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
        "        \n",
        "        Returns:\n",
        "        ------------\n",
        "        Tensor: Normalized image.\n",
        "        \"\"\"\n",
        "        for t, m, s in zip(tensor, self.mean, self.std):\n",
        "            t.mul_(s).add_(m)\n",
        "        return tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "QMAn7rEf9vrs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "lPicr7Bj99J3"
      },
      "outputs": [],
      "source": [
        "RANDOM_SEED = 123\n",
        "BATCH_SIZE = 8\n",
        "NUM_EPOCHS = 40\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "zZru4BqL-Civ"
      },
      "outputs": [],
      "source": [
        "set_all_seeds(RANDOM_SEED)\n",
        "#set_deterministic()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "YQ3HK-6i-Jln"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class scratch_vgg19(nn.Module):\n",
        "\t#  Determine what layers and their order in CNN object \n",
        "    def __init__(self):\n",
        "        super(scratch_vgg19, self).__init__()\n",
        "        self.conv_layer1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.max_pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.conv_layer2 = nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.max_pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.conv_layer3 = nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.max_pool3 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.conv_layer4 = nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.max_pool4 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.flat = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(100352, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, 2)\n",
        "    \n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.conv_layer1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.max_pool1(out)\n",
        "\n",
        "        out = self.conv_layer2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.max_pool2(out)\n",
        "                \n",
        "        out = self.conv_layer3(out)\n",
        "        out = self.relu3(out)\n",
        "        out = self.max_pool3(out)\n",
        "        \n",
        "        out = self.conv_layer4(out)\n",
        "        out = self.relu4(out)\n",
        "        out = self.max_pool4(out)\n",
        "        \n",
        "        out = self.flat(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "NkKzPpys0fpR"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_raw = scratch_vgg19()\n",
        "model_raw.load_state_dict(torch.load('/content/drive/MyDrive/PRML Project/covid 19/Weights_full_training/vgg19_full_30_04_93.34032440185547.pt')) # saurabh\n",
        "model_raw.to(DEVICE)\n",
        "\n",
        "model_mask = scratch_vgg19()\n",
        "model_mask.load_state_dict(torch.load('/content/drive/MyDrive/PRML Project/covid 19/Unet_M2_weights/vgg19_full_unetmask_01_05_87.2756118774414.pt')) # mitarth\n",
        "model_mask.to(DEVICE)\n",
        "\n",
        "model_inv_mask = scratch_vgg19()\n",
        "model_inv_mask.load_state_dict(torch.load('/content/drive/MyDrive/PRML Project/covid 19/Unet_M3_weights/vgg19_full_unetinvmask_01_05_91.28828430175781.pt')) # mukul\n",
        "model_inv_mask.to(DEVICE)"
      ],
      "metadata": {
        "id": "5MW2tJuU1fmi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8d2f063-fc45-41b5-a3a7-a0a448365a18"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scratch_vgg19(\n",
              "  (conv_layer1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu1): ReLU()\n",
              "  (max_pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv_layer2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu2): ReLU()\n",
              "  (max_pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv_layer3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu3): ReLU()\n",
              "  (max_pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv_layer4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu4): ReLU()\n",
              "  (max_pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=100352, out_features=4096, bias=True)\n",
              "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (fc3): Linear(in_features=4096, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# code to do the finetuning on the inference weights\n",
        "# torch.grad() types\n",
        "# reference\n",
        "# https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html"
      ],
      "metadata": {
        "id": "FkMqniMC195E"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "A84jBpyhiO9W"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class CombinedModelM4(nn.Module):\n",
        "  def __init__(self, model_raw, model_mask, model_inv_mask):\n",
        "    super().__init__()\n",
        "    # Note that the last layer for classification should be removed in both the models\n",
        "\n",
        "    # self.rawvgg = model_raw[:-4]\n",
        "    self.rawvgg  = nn.Sequential(*list(model_raw.children())[:-3])\n",
        "    self.maskvgg = nn.Sequential(*list(model_mask.children())[:-3])\n",
        "    self.invmaskvgg = nn.Sequential(*list(model_inv_mask.children())[:-3])\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "                                                  nn.Linear(in_features = 301056, out_features = 4096, bias = True),\n",
        "                                                  nn.ReLU(inplace = True),\n",
        "                                                  nn.Linear(in_features = 4096, out_features = 4096, bias = True),\n",
        "                                                  nn.ReLU(inplace=True),\n",
        "                                                  nn.Linear(in_features = 4096, out_features = 2, bias = True),\n",
        "                                              )\n",
        "    \n",
        "  def forward(self, cxr_raw,cxr_mask, cxr_inv):\n",
        "\n",
        "    rawvgg = self.rawvgg(cxr_raw).view(cxr_raw.shape[0], -1)\n",
        "    maskvgg = self.maskvgg(cxr_mask).view(cxr_mask.shape[0], -1)\n",
        "    inv_maskvgg = self.invmaskvgg(cxr_inv).view(cxr_inv.shape[0], -1)\n",
        "\n",
        "    combined_ft = torch.cat([rawvgg, maskvgg, inv_maskvgg], axis = -1)\n",
        "\n",
        "    out = self.classifier(combined_ft)\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = CombinedModelM4(model_raw, model_mask, model_inv_mask)\n",
        "model"
      ],
      "metadata": {
        "id": "YMyz86xW2U-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba9655ea-6875-47ff-87c4-121e8040dad4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CombinedModelM4(\n",
              "  (rawvgg): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU()\n",
              "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (9): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (10): ReLU()\n",
              "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (12): Flatten(start_dim=1, end_dim=-1)\n",
              "  )\n",
              "  (maskvgg): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU()\n",
              "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (9): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (10): ReLU()\n",
              "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (12): Flatten(start_dim=1, end_dim=-1)\n",
              "  )\n",
              "  (invmaskvgg): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU()\n",
              "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (9): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (10): ReLU()\n",
              "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (12): Flatten(start_dim=1, end_dim=-1)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=301056, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): Linear(in_features=4096, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all False and then unfreeze classifier layers\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "  \n",
        "model.classifier.requires_grad = True"
      ],
      "metadata": {
        "id": "tmdQ1Y4f8X_X"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), momentum=0.9, lr=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                       factor=0.1,\n",
        "                                                       mode='max',\n",
        "                                                       verbose=True)\n",
        "\n",
        "minibatch_loss_list, train_acc_list, valid_acc_list = train_model(\n",
        "    model=model,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    train_loader_raw=train_loader_raw,\n",
        "    valid_loader_raw=valid_loader_raw,\n",
        "    test_loader_raw=test_loader_raw,\n",
        "    train_loader_masked=train_loader_masked,\n",
        "    valid_loader_masked=valid_loader_masked,\n",
        "    test_loader_masked=test_loader_masked,\n",
        "    train_loader_invmasked=train_loader_invmasked,\n",
        "    valid_loader_invmasked=valid_loader_invmasked,\n",
        "    test_loader_invmasked=test_loader_invmasked,\n",
        "    optimizer=optimizer,\n",
        "    device=DEVICE,\n",
        "    scheduler=scheduler,\n",
        "    scheduler_on='valid_acc',\n",
        "    logging_interval=100)\n",
        "\n",
        "plot_training_loss(minibatch_loss_list=minibatch_loss_list,\n",
        "                   num_epochs=NUM_EPOCHS,\n",
        "                   iter_per_epoch=len(train_loader_raw),\n",
        "                   results_dir=None,\n",
        "                   averaging_iterations=200)\n",
        "plt.show()\n",
        "\n",
        "plot_accuracy(train_acc_list=train_acc_list,\n",
        "              valid_acc_list=valid_acc_list,\n",
        "              results_dir=None)\n",
        "plt.ylim([60, 100])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "ZHwVlksHiOEU",
        "outputId": "ec6bd0ac-5ea8-48ac-f7cd-17ef06681f10"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-598bab07b37f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mscheduler_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid_acc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     logging_interval=100)\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m plot_training_loss(minibatch_loss_list=minibatch_loss_list,\n",
            "\u001b[0;32m<ipython-input-18-33899a10b594>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, num_epochs, train_loader_raw, valid_loader_raw, test_loader_raw, train_loader_masked, valid_loader_masked, test_loader_masked, train_loader_invmasked, valid_loader_invmasked, test_loader_invmasked, optimizer, device, logging_interval, scheduler, scheduler_on)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m# ## UPDATE MODEL PARAMETERS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/PRML Project/covid 19/M4_weights/m4_02_05_final.pth')"
      ],
      "metadata": {
        "id": "Cc-1AZ42unf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.cpu()\n",
        "# unnormalizer = UnNormalize(mean, std)\n",
        "class_dict = {0: 'Covid',\n",
        "              1: 'Non-Covid'}\n",
        "show_examples(model=model, data_loader=test_loader_raw, unnormalizer=None, class_dict=class_dict)"
      ],
      "metadata": {
        "id": "ySzV4Zo8vk-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mat = compute_confusion_matrix(model=model, data_loader=test_loader_raw, device=torch.device('cpu'))\n",
        "plot_confusion_matrix(mat, class_names=class_dict.values())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iI8BLO5LvqdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Preparation"
      ],
      "metadata": {
        "id": "wjvkeCOo_-lo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "xQHiQwZSCL44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "for covid"
      ],
      "metadata": {
        "id": "SiD5Q3q_CdlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "craw_path = '/content/drive/MyDrive/PRML Project/covid 19/Extensive COVID-19 X-Ray and CT Chest Images Dataset.zip (Unzipped Files)/COVID-19 Dataset.zip (Unzipped Files)/COVID-19 Dataset/X-ray/COVID/'\n",
        "cmasked_path = '/content/drive/MyDrive/PRML Project/covid 19/masks/Covid/'\n",
        "cinv_masked_path = '/content/drive/MyDrive/PRML Project/covid 19/inverse_masks/Covid/'"
      ],
      "metadata": {
        "id": "IAdcR1KDCSDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "craw = np.array(os.listdir(craw_path))\n",
        "cmask = np.array(os.listdir(cmasked_path))\n",
        "cinv_mask = np.array(os.listdir(cinv_masked_path))"
      ],
      "metadata": {
        "id": "nH0E8tyg_UF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(craw), len(cmask), len(cinv_mask)"
      ],
      "metadata": {
        "id": "4UY1SycpC1pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Non-Covid"
      ],
      "metadata": {
        "id": "oQOYP_LpDGC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nraw_path = '/content/drive/MyDrive/PRML Project/covid 19/Extensive COVID-19 X-Ray and CT Chest Images Dataset.zip (Unzipped Files)/COVID-19 Dataset.zip (Unzipped Files)/COVID-19 Dataset/X-ray/Non-COVID/'\n",
        "nmasked_path = '/content/drive/MyDrive/PRML Project/covid 19/masks/Non-Covid/'\n",
        "ninv_masked_path = '/content/drive/MyDrive/PRML Project/covid 19/inverse_masks/Non-Covid/'"
      ],
      "metadata": {
        "id": "JBXsL4kGDAR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nraw = np.array(os.listdir(nraw_path))\n",
        "nmask = np.array(os.listdir(nmasked_path))\n",
        "ninv_mask = np.array(os.listdir(ninv_masked_path))"
      ],
      "metadata": {
        "id": "8bb5fVUYDgwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(nraw), len(nmask), len(ninv_mask)"
      ],
      "metadata": {
        "id": "GN-eHPFYDlbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus now best is to drop this extra 5500 - 5428 = 72 images from Non-Covid directory of cxr raw images"
      ],
      "metadata": {
        "id": "xF4XduYqF4aK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.remove('/content/drive/MyDrive/PRML Project/testing/streptococcus-pneumoniae-pneumonia-temporal-evolution-1-day3.jpg')"
      ],
      "metadata": {
        "id": "f3ICXeAIDo3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nrawl = list(nraw)\n",
        "nmaskl = list(nmask)\n",
        "ninvmaskl = list(ninv_mask)"
      ],
      "metadata": {
        "id": "Ba5EWdoTGRjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nraw_files = [os.path.splitext(i)[0] for i in nrawl]\n",
        "nmask_files = [os.path.splitext(i)[0] for i in nmaskl]\n",
        "ninvmask_files = [os.path.splitext(i)[0] for i in ninvmaskl] "
      ],
      "metadata": {
        "id": "ezbxrGjzFpb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nraw_ext = [os.path.splitext(i)[1] for i in nrawl]\n",
        "nmask_ext = [os.path.splitext(i)[1] for i in nmaskl]\n",
        "ninvmask_ext = [os.path.splitext(i)[1] for i in ninvmaskl] "
      ],
      "metadata": {
        "id": "m5SJMJmtIA7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rem_base_path = nraw_path"
      ],
      "metadata": {
        "id": "iMZr0VOhIMKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rem_base_path + nraw_files[0] + nraw_ext[0]"
      ],
      "metadata": {
        "id": "A_P1H6f1JTbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k=0\n",
        "rem_count=0\n",
        "for i in nraw_files:\n",
        "  if i not in nmask_files:\n",
        "    os.remove(rem_base_path + i + nraw_ext[k])\n",
        "    rem_count+=1\n",
        "  k+=1"
      ],
      "metadata": {
        "id": "OI7PZNk5Hnpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rem_count"
      ],
      "metadata": {
        "id": "kcw_U3gXKNCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(nraw_files)"
      ],
      "metadata": {
        "id": "k65vz_L8KQKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(nmask_files)"
      ],
      "metadata": {
        "id": "DaAMzIuxKaXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in nraw_files:\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "bOoUSMPgKgJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in nmask_files:\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "GJF0B_UAK2wW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'NORMAL2-IM-0906-0001' in nmask_files:\n",
        "  print(\"True\")"
      ],
      "metadata": {
        "id": "ZUysEYtOLCtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k=0\n",
        "add_count=0\n",
        "add=[]\n",
        "for i in nmask_files:\n",
        "  if i in nraw_files:\n",
        "    # os.remove(rem_base_path + i + nraw_ext[k])\n",
        "    add.append(i)\n",
        "    add_count+=1\n",
        "  k+=1"
      ],
      "metadata": {
        "id": "5hcnQKyMLc5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(add)"
      ],
      "metadata": {
        "id": "HIS3jFfmL7ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rem_list = []\n",
        "for i in add:\n",
        "  if i not in nraw_files:\n",
        "    rem_list.append(i)"
      ],
      "metadata": {
        "id": "2JfYyCSbL8vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(np.unique(nraw_files)), len(np.unique(nmask_files))"
      ],
      "metadata": {
        "id": "1G0t3fcINEE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l1 = [os.path.splitext(i)[0] for i in list(os.listdir('/content/drive/MyDrive/PRML Project/testing'))]"
      ],
      "metadata": {
        "id": "zaXxuabeNGr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l1"
      ],
      "metadata": {
        "id": "KJMbLzodPEp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nuraw = list(np.unique(nraw_files))\n",
        "numasks = list(np.unique(nmask_files))"
      ],
      "metadata": {
        "id": "6ZS8rh5DPFDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_rem_list = []\n",
        "for i in nraw_files:\n",
        "  if i not in nuraw:\n",
        "    raw_rem_list.append(i)"
      ],
      "metadata": {
        "id": "6xi0t5sHPajn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(raw_rem_list)"
      ],
      "metadata": {
        "id": "vSzR5bKMPs9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(nraw_files), len(nuraw)"
      ],
      "metadata": {
        "id": "Lg0vp3k4Pu--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n1, n2 = np.array(nraw_files), np.array(nuraw)"
      ],
      "metadata": {
        "id": "FBZKVyyqP1un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "difference_1 = np.setdiff1d(n1, n2)"
      ],
      "metadata": {
        "id": "EOMFZjwEQjEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "difference_1"
      ],
      "metadata": {
        "id": "P51jUhmBQp7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "preparation of dataset of 2500 noncovid images"
      ],
      "metadata": {
        "id": "r0CM9o0OW9uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_files = list(np.unique(list(os.listdir('/content/drive/MyDrive/PRML Project/covid 19/Extensive COVID-19 X-Ray and CT Chest Images Dataset.zip (Unzipped Files)/COVID-19 Dataset.zip (Unzipped Files)/COVID-19 Dataset/X-ray/Non-COVID/'))))\n",
        "masked_files = list(np.unique(list(os.listdir('/content/drive/MyDrive/PRML Project/covid 19/masks/Non-Covid/'))))\n",
        "invmasked_files = list(np.unique(list(os.listdir('/content/drive/MyDrive/PRML Project/covid 19/inverse_masks/Non-Covid/'))))"
      ],
      "metadata": {
        "id": "3U3LNkQLQrmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(raw_files), len(masked_files), len(invmasked_files)"
      ],
      "metadata": {
        "id": "DO0VmB95YEvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "idx = random.sample(range(5428), 2500)"
      ],
      "metadata": {
        "id": "99I8ZsZzYKUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(idx)"
      ],
      "metadata": {
        "id": "8Vq7zj8XYz2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k=0\n",
        "for i in raw_files:\n",
        "  if (i in masked_files) and (i in invmasked_files):\n",
        "    k+=1"
      ],
      "metadata": {
        "id": "TCbyLFtiY0l2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k"
      ],
      "metadata": {
        "id": "ffFvcy_6ZFRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files_list = []\n",
        "k=0\n",
        "for i in raw_files:\n",
        "  if (i in masked_files) and (i in invmasked_files):\n",
        "    files_list.append(i)\n",
        "    k+=1\n",
        "  if(k==2500):\n",
        "    break"
      ],
      "metadata": {
        "id": "-xsfpywrZFn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(files_list)"
      ],
      "metadata": {
        "id": "OZylH3qaZwgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "J_kij_5baJiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in files_list:\n",
        "  raw_img = cv2.imread('/content/drive/MyDrive/PRML Project/covid 19/Extensive COVID-19 X-Ray and CT Chest Images Dataset.zip (Unzipped Files)/COVID-19 Dataset.zip (Unzipped Files)/COVID-19 Dataset/X-ray/Non-COVID/' + i)\n",
        "  masked_img = cv2.imread('/content/drive/MyDrive/PRML Project/covid 19/masks/Non-Covid/' + i)\n",
        "  invmasked_img = cv2.imread('/content/drive/MyDrive/PRML Project/covid 19/inverse_masks/Non-Covid/' + i)\n",
        "\n",
        "  cv2.imwrite('/content/drive/MyDrive/PRML Project/covid 19/Combinedmodel_Dataset/raw_cxr/Non-Covid/' + i, raw_img)    \n",
        "  cv2.imwrite('/content/drive/MyDrive/PRML Project/covid 19/Combinedmodel_Dataset/masked_cxr/Non-Covid/' + i, masked_img)    \n",
        "  cv2.imwrite('/content/drive/MyDrive/PRML Project/covid 19/Combinedmodel_Dataset/invmasked_cxr/Non-Covid/' + i, invmasked_img)    "
      ],
      "metadata": {
        "id": "5hWpqHVKZy1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir('/content/drive/MyDrive/PRML Project/covid 19/Combinedmodel_Dataset/raw_cxr/Non-Covid/'))\n",
        "len(os.listdir('/content/drive/MyDrive/PRML Project/covid 19/Combinedmodel_Dataset/masked_cxr/Non-Covid/'))\n",
        "len(os.listdir('/content/drive/MyDrive/PRML Project/covid 19/Combinedmodel_Dataset/invmasked_cxr/Non-Covid/'))"
      ],
      "metadata": {
        "id": "bfEGPrz6jcHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2500 Images for Covid"
      ],
      "metadata": {
        "id": "-ai3lf9nc3JG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2"
      ],
      "metadata": {
        "id": "gW85z3Kzdml-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "craw_files = list(np.unique(list(os.listdir('/content/drive/MyDrive/PRML Project/covid 19/Extensive COVID-19 X-Ray and CT Chest Images Dataset.zip (Unzipped Files)/COVID-19 Dataset.zip (Unzipped Files)/COVID-19 Dataset/X-ray/COVID/'))))\n",
        "cmasked_files = list(np.unique(list(os.listdir('/content/drive/MyDrive/PRML Project/covid 19/masks/Covid/'))))\n",
        "cinvmasked_files = list(np.unique(list(os.listdir('/content/drive/MyDrive/PRML Project/covid 19/inverse_masks/Covid/'))))"
      ],
      "metadata": {
        "id": "WL09j-Ulb99V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(craw_files), len(cmasked_files), len(cinvmasked_files)"
      ],
      "metadata": {
        "id": "vzLACscUdkZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k=0\n",
        "for i in craw_files:\n",
        "  if (i in cmasked_files) and (i in cinvmasked_files):\n",
        "    k+=1"
      ],
      "metadata": {
        "id": "4Z7bczR6d0-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k"
      ],
      "metadata": {
        "id": "ZWCQDK89eFtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "idx = random.sample(range(4044), 2500)"
      ],
      "metadata": {
        "id": "l1gdFMR7eGE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(np.unique(idx))"
      ],
      "metadata": {
        "id": "AGE7YenNeOle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfiles_list = []\n",
        "k=0\n",
        "for i in craw_files:\n",
        "  if (i in cmasked_files) and (i in cinvmasked_files):\n",
        "    cfiles_list.append(i)\n",
        "    k+=1\n",
        "  if(k==2500):\n",
        "    break"
      ],
      "metadata": {
        "id": "90fbPbLIeUZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(cfiles_list)"
      ],
      "metadata": {
        "id": "Q5EjR8WTek42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in cfiles_list:\n",
        "  craw_img = cv2.imread('/content/drive/MyDrive/PRML Project/covid 19/Extensive COVID-19 X-Ray and CT Chest Images Dataset.zip (Unzipped Files)/COVID-19 Dataset.zip (Unzipped Files)/COVID-19 Dataset/X-ray/COVID/' + i)\n",
        "  cmasked_img = cv2.imread('/content/drive/MyDrive/PRML Project/covid 19/masks/Covid/' + i)\n",
        "  cinvmasked_img = cv2.imread('/content/drive/MyDrive/PRML Project/covid 19/inverse_masks/Covid/' + i)\n",
        "\n",
        "  cv2.imwrite('/content/drive/MyDrive/PRML Project/covid 19/Combinedmodel_Dataset/raw_cxr/Covid/' + i, craw_img)    \n",
        "  cv2.imwrite('/content/drive/MyDrive/PRML Project/covid 19/Combinedmodel_Dataset/masked_cxr/Covid/' + i, cmasked_img)    \n",
        "  cv2.imwrite('/content/drive/MyDrive/PRML Project/covid 19/Combinedmodel_Dataset/invmasked_cxr/Covid/' + i, cinvmasked_img)    "
      ],
      "metadata": {
        "id": "jTNIvDkKeo6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir('/content/drive/MyDrive/PRML Project/covid 19/Combinedmodel_Dataset/raw_cxr/Covid/'))"
      ],
      "metadata": {
        "id": "awy1MP-cfDr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir('/content/drive/MyDrive/PRML Project/covid 19/Combinedmodel_Dataset/masked_cxr/Covid/'))"
      ],
      "metadata": {
        "id": "ifBI5uJYi9bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir('/content/drive/MyDrive/PRML Project/covid 19/Combinedmodel_Dataset/invmasked_cxr/Covid/'))"
      ],
      "metadata": {
        "id": "BoDTo_BkjLNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "I_JbOhNKj1QC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_GoLLqLQjO9k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}